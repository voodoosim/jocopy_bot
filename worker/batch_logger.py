"""Batch Logging System (Optimization Phase 3)

This module implements a batch logging system to reduce database load.
Instead of inserting logs one-by-one, logs are buffered and inserted in batches.

Key Benefits:
- Reduces DB INSERT operations by 70-90%
- Automatic flush every N seconds
- Automatic flush when buffer reaches size limit
- Graceful shutdown with final flush

Architecture:
- Buffer: In-memory list of pending logs
- Auto-flush task: Background task that flushes every N seconds
- Size-based flush: Immediate flush when buffer size exceeds limit
- Manual flush: Can be called explicitly

Usage:
    logger = BatchLogger(flush_interval=5, batch_size=50)
    await logger.log(worker_id, worker_name, "INFO", "Message")
    # ... logs are buffered ...
    # Auto-flush after 5 seconds or 50 logs, whichever comes first
    await logger.shutdown()  # Graceful shutdown
"""

import logging
import asyncio
import aiosqlite
from typing import List, Tuple
from datetime import datetime

from config import DATABASE_PATH

logger = logging.getLogger(__name__)


class BatchLogger:
    """Batch logging system with automatic and manual flushing.

    Attributes:
        buffer: In-memory buffer of pending logs
        flush_interval: Seconds between auto-flushes
        batch_size: Max buffer size before auto-flush
        _flush_task: Background task for periodic flushing
        _shutdown: Shutdown flag
    """

    def __init__(self, flush_interval: int = 5, batch_size: int = 50):
        """Initialize batch logger.

        Args:
            flush_interval: Seconds between auto-flushes (default: 5)
            batch_size: Buffer size limit (default: 50)
                       When buffer reaches this size, flush immediately
        """
        self.buffer: List[Tuple[int, str, str, str, str]] = []
        self.flush_interval = flush_interval
        self.batch_size = batch_size
        self._shutdown = False
        self._lock = asyncio.Lock()  # Thread-safe buffer access

        # Start background flush task
        self._flush_task = asyncio.create_task(self._auto_flush_loop())

        logger.info(
            f"ðŸ“¦ [Optimization Phase 3] BatchLogger initialized "
            f"(interval={flush_interval}s, batch_size={batch_size})"
        )

    async def log(self, worker_id: int, worker_name: str, level: str, message: str):
        """Add log entry to buffer.

        Args:
            worker_id: Worker identifier
            worker_name: Worker name (for display)
            level: Log level (INFO, WARNING, ERROR, SUCCESS, START, STOP)
            message: Log message text

        Note:
            - Logs are buffered in memory
            - Auto-flush when buffer size >= batch_size
            - Auto-flush every flush_interval seconds
        """
        async with self._lock:
            # Add to buffer with timestamp
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            self.buffer.append((worker_id, worker_name, level, message, timestamp))

            # Size-based flush
            if len(self.buffer) >= self.batch_size:
                await self._flush()

    async def _flush(self):
        """Flush buffer to database (internal, requires lock).

        This method should be called while holding self._lock.
        Inserts all buffered logs in a single transaction.
        """
        if not self.buffer:
            return

        try:
            # Batch insert (much faster than individual INSERTs)
            async with aiosqlite.connect(DATABASE_PATH) as db:
                await db.executemany(
                    """
                    INSERT INTO logs (worker_id, worker_name, level, message, created_at)
                    VALUES (?, ?, ?, ?, ?)
                    """,
                    self.buffer
                )
                await db.commit()

            count = len(self.buffer)
            logger.debug(f"âœ… [BatchLogger] Flushed {count} logs to DB")
            self.buffer.clear()

        except Exception as e:
            logger.error(f"âŒ [BatchLogger] Flush failed: {e}")
            # Keep buffer for retry on next flush
            # Do NOT clear buffer on error

    async def _auto_flush_loop(self):
        """Background task: Auto-flush every N seconds.

        Runs until shutdown() is called.
        """
        logger.info(f"ðŸ”„ [BatchLogger] Auto-flush task started (interval={self.flush_interval}s)")

        while not self._shutdown:
            await asyncio.sleep(self.flush_interval)

            async with self._lock:
                if self.buffer:
                    await self._flush()

        logger.info("ðŸ›‘ [BatchLogger] Auto-flush task stopped")

    async def flush(self):
        """Manually flush buffer to database (public API).

        Use Cases:
            - Before critical operations
            - During testing
            - Before shutdown
        """
        async with self._lock:
            await self._flush()

    async def shutdown(self):
        """Gracefully shutdown batch logger.

        Steps:
            1. Set shutdown flag
            2. Cancel auto-flush task
            3. Flush remaining buffer
            4. Wait for task completion

        Always call this before exiting to ensure no logs are lost.
        """
        logger.info("ðŸ›‘ [BatchLogger] Shutting down...")
        self._shutdown = True

        # Cancel auto-flush task
        if self._flush_task and not self._flush_task.done():
            self._flush_task.cancel()
            try:
                await self._flush_task
            except asyncio.CancelledError:
                pass

        # Final flush
        async with self._lock:
            if self.buffer:
                logger.info(f"ðŸ“¤ [BatchLogger] Final flush: {len(self.buffer)} logs")
                await self._flush()

        logger.info("âœ… [BatchLogger] Shutdown complete")

    def get_stats(self) -> dict:
        """Get batch logger statistics.

        Returns:
            dict: Statistics
                - buffer_size: Current number of buffered logs
                - batch_size: Max buffer size
                - flush_interval: Auto-flush interval (seconds)
        """
        return {
            "buffer_size": len(self.buffer),
            "batch_size": self.batch_size,
            "flush_interval": self.flush_interval
        }
